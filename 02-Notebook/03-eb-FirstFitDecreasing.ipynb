{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bak = pd.read_excel('../01-Data/ordens_pre_process.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_bak.drop(['Unnamed: 0'], axis=1)\n",
    "df.columns = df.columns.str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['Inner'] == 1]\n",
    "df = df[df['Loja'] == 6]\n",
    "df = df[df['Classe_de_onda'] == 4]\n",
    "df = df[df['Tipo_de_buffer'] == 'CX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "print(df['Inner'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 53 entries, 3935 to 31314\n",
      "Data columns (total 22 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   Ordem_de_produção          53 non-null     int64         \n",
      " 1   Data_da_ordem_de_produção  53 non-null     datetime64[ns]\n",
      " 2   Produto                    53 non-null     int64         \n",
      " 3   Comprimento_unit           53 non-null     int64         \n",
      " 4   Largura_unit               53 non-null     int64         \n",
      " 5   Altura_unit                53 non-null     int64         \n",
      " 6   Peso_unit                  53 non-null     float64       \n",
      " 7   Peças                      53 non-null     int64         \n",
      " 8   Caixa_padrão               53 non-null     object        \n",
      " 9   Loja                       53 non-null     int64         \n",
      " 10  Classe_de_onda             53 non-null     int64         \n",
      " 11  Tipo_de_buffer             53 non-null     object        \n",
      " 12  Item_pai                   53 non-null     int64         \n",
      " 13  Cor                        53 non-null     float64       \n",
      " 14  Tamanho                    53 non-null     int64         \n",
      " 15  Inner                      53 non-null     int64         \n",
      " 16  Rota                       53 non-null     int64         \n",
      " 17  Capacidade                 53 non-null     float64       \n",
      " 18  pai-cor                    53 non-null     object        \n",
      " 19  Volume_unit                53 non-null     int64         \n",
      " 20  Volume_total               53 non-null     int64         \n",
      " 21  Peso_total                 53 non-null     float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(14), object(3)\n",
      "memory usage: 9.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def first_fit_decreasing(df, bin_capacity_vol, bin_capacity_weight, bin_item_limit):\n",
    "    # Sort items in decreasing order of volume\n",
    "    df_sorted = df.sort_values(by='Volume_total', ascending=False)\n",
    "    \n",
    "    # Initialize bins list\n",
    "    bins = []\n",
    "    \n",
    "    # Flag to track if a split was made\n",
    "    split_made = True\n",
    "    items_to_drop = []\n",
    "    df_sorted = df_sorted.reset_index(drop=True)\n",
    "    items_to_add = []\n",
    "\n",
    "      \n",
    "    while len(df_sorted) != 0:\n",
    "        split_made = False\n",
    "\n",
    "        df_sorted = df_sorted[~df_sorted.index.isin(items_to_drop)]\n",
    "\n",
    "        # Add needed items to df_sorted\n",
    "        if len(items_to_add) != 0:\n",
    "            df_sorted = pd.concat([df_sorted, pd.DataFrame(items_to_add)])\n",
    "        items_to_add = []\n",
    "        \n",
    "        df_sorted = df_sorted.reset_index(drop=True)\n",
    "        items_to_drop = []\n",
    "        \n",
    "        # Make a copy of the sorted DataFrame\n",
    "        df_sorted_copy = df_sorted.copy()\n",
    "        # Iterate over items in the copy of the sorted DataFrame\n",
    "        for index, item in df_sorted_copy.iterrows():\n",
    "            # Flag to check if the item is placed\n",
    "            placed = False\n",
    "            \n",
    "            # Try to place the item in existing bins\n",
    "            for bin in bins:\n",
    "                if (bin['Volume'] + item['Volume_total']) <= bin_capacity_vol \\\n",
    "                   and (bin['Peso_total'] + item['Peso_total']) <= bin_capacity_weight \\\n",
    "                   and bin['Amt.Items'] + item['Peças'] <= bin_item_limit:\n",
    "                    bin['Items'].append(index)\n",
    "                    bin['Volume'] += item['Volume_total']\n",
    "                    bin['Peso_total'] += item['Peso_total']\n",
    "                    bin['Amt.Items'] += item['Peças']\n",
    "\n",
    "                    # Remove the item from the original DataFrame\n",
    "                    items_to_drop.append(index)\n",
    "\n",
    "                    placed = True\n",
    "                    break\n",
    "            \n",
    "            # If the item couldn't be placed entirely, reduce it by \"inner\" means until it fits into a bin\n",
    "            while not placed and item['Peças'] > item['Inner']:\n",
    "                # Reduce the item to its inner size\n",
    "                detached_portion = item.copy()\n",
    "                detached_portion['Peças'] = item['Inner']\n",
    "                detached_portion['Volume_total'] = item['Volume_unit'] * item['Inner']\n",
    "                detached_portion['Peso_total'] = item['Peso_unit'] * item['Inner']\n",
    "                \n",
    "                # Update the remaining portion of the item\n",
    "                item['Peças'] -= item['Inner']\n",
    "                item['Volume_total'] -= item['Volume_unit'] * item['Inner']\n",
    "                item['Peso_total'] -= item['Peso_unit'] * item['Inner']\n",
    "                \n",
    "                # Concatenate the reduced portion back to the original DataFrame\n",
    "                items_to_add.append(detached_portion)\n",
    "                split_made = True\n",
    "                \n",
    "                # Try to place the reduced item in existing bins\n",
    "                for bin in bins:\n",
    "                    if (bin['Volume'] + item['Volume_total']) <= bin_capacity_vol \\\n",
    "                       and (bin['Peso_total'] + item['Peso_total']) <= bin_capacity_weight \\\n",
    "                       and bin['Amt.Items'] + item['Peças'] <= bin_item_limit:\n",
    "                        bin['Items'].append(index)  # Append index of the appended reduced item\n",
    "                        bin['Volume'] += item['Volume_total']\n",
    "                        bin['Peso_total'] += item['Peso_total']\n",
    "                        bin['Amt.Items'] += item['Peças']\n",
    "\n",
    "                        items_to_drop.append(index) # Remove the reduced item from the original DataFrame\n",
    "                        placed = True\n",
    "                        break\n",
    "            \n",
    "            # If the item still couldn't be placed, create a new bin\n",
    "            if not placed:\n",
    "                bins.append({'Items': [index], 'Volume': item['Volume_total'], 'Peso_total': item['Peso_total'], 'Amt.Items': item['Peças']})\n",
    "                items_to_drop.append(index)\n",
    "                placed = True\n",
    "                break\n",
    "    \n",
    "    return bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def old_first_fit_decreasing(df, bin_capacity_vol, bin_capacity_weight, bin_item_limit):\n",
    "    # Sort items in decreasing order of volume\n",
    "    df_sorted = df.sort_values(by='Volume_total', ascending=False)\n",
    "    \n",
    "    # Initialize bins list\n",
    "    bins = []\n",
    "    \n",
    "    for index, item in df_sorted.iterrows():\n",
    "        for bin in bins:\n",
    "            if (bin['Volume'] + item['Volume_total']) <= bin_capacity_vol and \\\n",
    "                (bin['Peso_total'] + item['Peso_total']) <= bin_capacity_weight and \\\n",
    "                bin['Amt.Items'] <= bin_item_limit:\n",
    "                    bin['Items'].append(index)\n",
    "                    bin['Volume'] += item['Volume_total']\n",
    "                    bin['Peso_total'] += item['Peso_total']\n",
    "                    bin['Amt.Items'] += item['Peças']\n",
    "                    break\n",
    "        else:\n",
    "            # Create new bin\n",
    "            bins.append({'Items': [index], 'Volume': item['Volume_total'], 'Peso_total': item['Peso_total'], 'Amt.Items': item['Peças']})\n",
    "    \n",
    "    return bins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packed bins (new method):\n",
      "Bin 1: Amt. Items 18 (Total Volume: 82794797 cubic mm | Total Weight: 5.1000kg)\n",
      "Bin 2: Amt. Items 27 (Total Volume: 83323287 cubic mm | Total Weight: 11.1070kg)\n",
      "Bin 3: Amt. Items 23 (Total Volume: 82950539 cubic mm | Total Weight: 9.7860kg)\n",
      "Bin 4: Amt. Items 30 (Total Volume: 81909153 cubic mm | Total Weight: 8.8310kg)\n",
      "Bin 5: Amt. Items 6 (Total Volume: 27054084 cubic mm | Total Weight: 1.5800kg)\n",
      "\n",
      "Packed bins (old method):\n",
      "Bin 1: Amt. Items 20 (Total Volume: 83375243 cubic mm | Total Weight: 5.6400kg)\n",
      "Bin 2: Amt. Items 24 (Total Volume: 83013681 cubic mm | Total Weight: 7.9740kg)\n",
      "Bin 3: Amt. Items 21 (Total Volume: 83186828 cubic mm | Total Weight: 10.7000kg)\n",
      "Bin 4: Amt. Items 27 (Total Volume: 82529145 cubic mm | Total Weight: 8.5450kg)\n",
      "Bin 5: Amt. Items 12 (Total Volume: 25926963 cubic mm | Total Weight: 3.5450kg)\n"
     ]
    }
   ],
   "source": [
    "bin_capacity_vol = 83393894.40\n",
    "bin_capacity_weight = 23\n",
    "bin_item_limit = 170\n",
    "packed_bins_new = first_fit_decreasing(df, bin_capacity_vol, bin_capacity_weight, bin_item_limit)\n",
    "packed_bins_old = old_first_fit_decreasing(df, bin_capacity_vol, bin_capacity_weight, bin_item_limit)\n",
    "print(\"Packed bins (new method):\")\n",
    "for i, bin in enumerate(packed_bins_new):\n",
    "    print(f\"Bin {i+1}: Amt. Items {bin['Amt.Items']} (Total Volume: {bin['Volume']} cubic mm | Total Weight: {bin['Peso_total'] :.4f}kg)\")\n",
    "\n",
    "print(\"\\nPacked bins (old method):\")\n",
    "for i, bin in enumerate(packed_bins_old):\n",
    "    print(f\"Bin {i+1}: Amt. Items {bin['Amt.Items']} (Total Volume: {bin['Volume']} cubic mm | Total Weight: {bin['Peso_total'] :.4f}kg)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
